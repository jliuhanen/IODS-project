---
title: "Chapter6.Rmd"
author: "JL"
date: "7 12 2021"
output: html_document
---

# Chapter 6: Analysis of longitudinal data

In this exercise, we are first going to analyse longitudinal data using the dataset called rats. Rats is a nutrition study conducted in three groups of rats. The three groups were on different diets and each animal's body weight was recorded approximately weekly during a 9 week period. In the analyses, we are going to examine whether the different diets have a statistically significant effect on the rats' weights.

First, we are going to explore the data set graphically.

```{r}
#First activating the libraries needed in this exercise
library(ggplot2)
library(tidyr)
library(dplyr)

#Reading the data into R in long form, and checking the dimensions and structure of the data.
ratsL <- read.table("data/ratsL.txt")
dim(ratsL)
str(ratsL)

#Converting categorical variables to factors (ID & Group)
ratsL$ID <- factor(ratsL$ID)
ratsL$Group <- factor(ratsL$Group)

#Drawing the first plot of the data set using unstandardized weight
ggplot(ratsL, aes(x = Time, y = Weight, group = ID)) +
  geom_line(aes(color = Group)) +
  scale_x_continuous(name = "Time (days)", breaks = seq(0, 60, 10)) +
  scale_y_continuous(name = "Weight (grams)") +
  theme(legend.position = "top")
```

In this first figure each rat is represented by one line. The colour of the line indicates the group the rat belongs to. From the plot we can see that the rats in Group 1 (red lines) are clearly lighter than rats in the other two groups. Rats in Group 2 (green lines) seems to be in the middle (expect for one rat, which is the heaviest of all), and Group 3 (blue lines) rats the heaviest. These differences in weight are present already at the baseline. Next, we will draw a similar figure with standardized weights.
```{r}
# Standardise the variable Weight
ratsL <- ratsL %>%
  group_by(Time) %>%
  mutate(stdweight = (Weight - mean(Weight))/sd(Weight) ) %>%
  ungroup()

# Glimpse the data
glimpse(ratsL)

#The figure again with standardized weight variables
ggplot(ratsL, aes(x = Time, y = stdweight, group = ID)) +
  geom_line(aes(color = Group)) +
  scale_x_continuous(name = "Time (days)", breaks = seq(0, 60, 10)) +
  scale_y_continuous(name = "Weight (grams)") +
  theme(legend.position = "top")
```

After standardizing the weight variable, the figure looks very similar to the first figure with unstandardized weights. The biggest difference might be that the rats' weight does not seem to increase bytime any more, as it appeared to do in the first figure.

Next, we will draw a plot with group mean values (and standard errors).

```{r}
# Number of subjects (per group):
n <- 20

# Summary data with mean and standard error 
ratsLS <- ratsL %>%
  group_by(Group, Time) %>%
 summarise( mean = mean(Weight), se = sd(Weight)/sqrt(n) ) %>%
  ungroup()

# Plot the mean profiles
ggplot(ratsLS, aes(x = Time, y = mean, linetype = Group, shape = Group)) +
  geom_line() +
  scale_linetype_manual(values = c(1,2,3)) +
  geom_point(size=3) +
  scale_shape_manual(values = c(1,2,3)) +
  geom_errorbar(aes(ymin = mean - se, ymax = mean + se, linetype="1"), width=0.3) +
  theme(legend.position = c(0.9,0.5)) +
  scale_y_continuous(name = "mean(Weight) +/- se(Weight)")
```

In this figure, each of the three groups are represented by one line (which represents the mean weight of that group over time). Means and standard errors are drawn as symbols and error bars around the means in the figure. From this figure we can see that Group 1 has clearly the lightest rats. Group 2 and group 3 are more close to each other, but the rats in group 3 have higher mean weight than rats in group 2. 

Next, we will draw a boxplot (in order to see whether there are outliers in the data).

```{r}
#Create a boxplot

# Create a summary data by Group and subject with mean as the summary variable (ignoring baseline week 0).
ratsL8s <- ratsL %>%
  filter(Time > 1) %>%
  group_by(Group, ID) %>%
  summarise( mean=mean(Weight) ) %>%
  ungroup()

# Glimpse the data
#glimpse(ratsL8s)

# Draw a boxplot of the mean versus treatment
ggplot(ratsL8s, aes(x = Group, y = mean)) +
  geom_boxplot() +
  stat_summary(fun = "mean", geom = "point", shape=23, size=4, fill = "white") +
  scale_y_continuous(name = "mean(Weight)")

```

The three groups of rats are represented as boxes in the figure. From the boxplot we can see that there are outliers in the data. In every group, there is one outlier (Group 1 < 250 g, Group 2 > 550 g, Group 3 < 500 g). These outliers could be removed before further analysis of the data, because they might bias the conclusions made from the subsequent analysis, for example analysis of covariance. But, because the data is so limited (only 4 rats in Group 2 and Group 3), we will not remove any outliers.

Next, we will examine with analysis of variance, whether the nutrition groups have a statistically significant effect on the rats' weights.

```{r}
#For this analysis we need also the raw rats data
rats <- read.table("https://raw.githubusercontent.com/KimmoVehkalahti/MABS/master/Examples/data/rats.txt")

#str(rats)

# Add the baseline from the original data as a new variable to the summary data
ratsL8s2 <- ratsL8s %>%
  mutate(baseline = rats$WD1)

#str(ratsL8s2)

# Fit the linear model with the mean as the response 
fit <- lm(mean ~ baseline + Group, data = ratsL8s2)

# Compute the analysis of variance table for the fitted model with anova()
anova(fit)

```

In the analysis of variance we examined whether baseline (weight) and Group had a statistically significant effect on the mean weight of rats. The degrees of freedom (df) tell us that there were 3 groups in total. F value is the test statistic calculated for baseline and Group, and the Pr(>F) column tells us whether the effect of baseline or Group is statistically significant (if we use alpha-level of 0.05, then the p-values < 0.05 are statistically significant). Baseline has a statistically significant effect on the mean weight of rats, but Group does not (although it is close of being significant). So, we conclude that the different diets did not have an effect on the rats' weights. In other words, whether the rat belonged to group 1, 2 or 3, did not affect its weight.


ANALYSIS OF THE BPRS DATA
In the second part of this exercise, we are going to analyze another longitudinal dataset, the bprs data. Bprs is a dataset of clinical trial of 40 males, who were randomly assigned to two treatment groups and assessed with brief psychiatric rating scale (BPRS) weekly during a 8 week period.
First, we will explore the data graphically.

```{r}
#Activating libraries needed
library(lme4)

#Reading the data into R in long form, and checking the dimensions and structure of the data.
bprsL <- read.table("data/bprsL.txt")
#dim(bprsL)
#str(bprsL)

#Converting categorical variables to factors (treatment & subject)
bprsL$treatment <- factor(bprsL$treatment)
bprsL$subject <- factor(bprsL$subject)

# Draw the plot 
ggplot(bprsL, aes(x = week, y = bprs, linetype = subject)) +
  geom_line() +
  scale_linetype_manual(values = rep(1:10, times=4)) +
  facet_grid(. ~ treatment, labeller = label_both) +
  theme(legend.position = "none") + 
  scale_y_continuous(limits = c(min(bprsL$bprs), max(bprsL$bprs)))
```

In this first plot every line represents one individual and his measurements on bprs during the 8 week period. On the left is treatment group 1 and on the right is treatment group 2. On the basis of this figure it seems that in treatment group 1 the bprs scores tend to get smaller during the 8 week period, but the same is not true, at least as much, in the treatment group 2.

```{r}

#Drawing a plot
ggplot(bprsL, aes(x = week, y = bprs, linetype = subject)) +
  geom_line(aes(color = treatment))
```

In the second plot, all the subjects are depicted in the same plot, and, again every line represents one subject in the dataset. The different colours represent treatment groups 1 and 2. It is difficult to see from this figure, whether treatment has an effect on the outcome (bprs).

Next, we will run regression analysis on the data.
First, we will run a basic regression model.

```{r}

# create a regression model bprs_reg
bprs_reg <- lm(bprs ~ week + treatment, data = bprsL)

# print out a summary of the model
summary(bprs_reg)  
```

In the basic regression model week seems to be a significant predictor of bprs, but treatment does not. In other words, time (week) affects significantly the bprs scores, but the two treatments do not differ in their effects.

Next, we will run a random intercept model, and, a random intercept and random slope model, and compare these models.

```{r}

# Create a random intercept model
bprs_ref <- lmer(bprs ~ week + treatment + (1 | subject), data = bprsL, REML = FALSE)

# Print the summary of the model
summary(bprs_ref)

# create a random intercept and random slope model
bprs_ref1 <- lmer(bprs ~ week + treatment + (week | subject), data = bprsL, REML = FALSE)

# print a summary of the model
summary(bprs_ref1)

# perform an ANOVA test on the two models
anova(bprs_ref1, bprs_ref)
```
The model comparisons show that bringing the slope to the model improves the model significantly (the p-value for Chisq test is < 0.05). The AIC and BIC values are close to each other in both of the models (the model with smaller AIC and BIC values are usually preferred).

Next, we will add an interaction term into the model (week*treatment). 

```{r}

# create a random intercept and random slope model
bprs_ref2 <- lmer(bprs ~ week * treatment + (week | subject), data = bprsL, REML = FALSE)

# print a summary of the model
summary(bprs_ref2)

# perform an ANOVA test on the two models
anova(bprs_ref2, bprs_ref1)

```

Adding an interaction term to the model did not significantly improve the model (p-value for Qhisq test is > 0.05), so including the interaction to the model is not a good idea. The t-value for the interaction term is not very big, so it is not likely that it is significant. In all, based on the regression models it seems that week is a significant predictor of bprs, but treatment is not, and there is no significant interaction between week and treatment on the bprs score.
